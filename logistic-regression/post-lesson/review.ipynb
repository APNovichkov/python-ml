{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review of Logistic Regression\n",
    "This is yet another classifier model, and is different from SVM in that it tries to fit a logarithmic  \n",
    "curve through the data where the data is represented with 1 and 0 on the y axis and dots on the x axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. We are going to train our model with only 4 of these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']\n",
    "feature_df = df[feature_cols]\n",
    "\n",
    "X = feature_df.to_numpy()\n",
    "y = df['Outcome'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=0)\n",
    "\n",
    "log_reg = LogisticRegression(solver='lbfgs')\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With logistic regression we can just do the normal predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUT! Because logistic regression fits a logorithmic curve through the data between 0 and 1, we can ask it to tell us the probability of the condition being 1 or 0 based on the feature value(s). This is the true power of logistic regression, because we can manually set thresholds for what probability we consider to the outcome to be 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61405867, 0.38594133],\n",
       "       [0.7505398 , 0.2494602 ],\n",
       "       [0.74167648, 0.25832352],\n",
       "       [0.60291327, 0.39708673]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = log_reg.predict_proba(X_test)\n",
    "y_pred_prob[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that for the first row for example, the probability of the outcome being 0 is .61, and for 1 it is .38. If we want to find out what the cols are, we can say log_reg.classes_ to get the col names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a confusion matrix, which is used to measure how good the model is\n",
    "We can use Sklearn again to get a confusion matrix. A confusion matrix is basically this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted:    0   1  \n",
    "# Actual:    0 TN  FP    \n",
    "# Actual:    1 FN  TP  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where:  \n",
    "TN - True Negatives  \n",
    "TP - True Positives  \n",
    "FN - False Negatives  \n",
    "FP - False Positives   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[114,  46],\n",
       "       [ 16,  16]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "c_matrix = metrics.confusion_matrix(y_pred, y_test)\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Find f1 score of the model\n",
    "We can again use sklearn for this, or use our own functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(confusion_matrix):\n",
    "    # TP + TN\n",
    "    total = confusion_matrix.sum().sum()\n",
    "    tp_plus_tn = confusion_matrix[1][1] + confusion_matrix[0][0]\n",
    "    return tp_plus_tn/total\n",
    "\n",
    "def get_error(confusion_matrix):\n",
    "    # FP + FN\n",
    "    total = confusion_matrix.sum().sum()\n",
    "    fp_plus_fn = confusion_matrix[0][1] + confusion_matrix[0][0]\n",
    "    return fp_plus_fn/total\n",
    "\n",
    "def get_recall(confusion_matrix):\n",
    "    # TP / (TP + FN)\n",
    "    tp_plus_tn = confusion_matrix[1][1] + confusion_matrix[0][1]\n",
    "    tp = confusion_matrix[1][1]\n",
    "    return tp/tp_plus_tn\n",
    "\n",
    "def get_specificity(confusion_matrix):\n",
    "    # TN / (TN + FN)\n",
    "    tn_plus_fn = confusion_matrix[0][0] + confusion_matrix[0][1]\n",
    "    tn = confusion_matrix[0][0]\n",
    "    return tn/tn_plus_fn\n",
    "\n",
    "def get_precision(confusion_matrix):\n",
    "    # TP / (TP + FP)\n",
    "    tp_plus_fp = confusion_matrix[1][1] + confusion_matrix[1][0]\n",
    "    tp = confusion_matrix[1][1]\n",
    "    return tp/tp_plus_fp\n",
    "\n",
    "def get_f1_score(confusion_matrix):\n",
    "    numerator = 2*get_precision(confusion_matrix) * get_recall(confusion_matrix)\n",
    "    denominator = get_precision(confusion_matrix) + get_recall(confusion_matrix)\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of our model: 0.3404255319148936\n",
      "With confusion matrix: \n",
      "[[114  46]\n",
      " [ 16  16]]\n"
     ]
    }
   ],
   "source": [
    "print(f'F1 score of our model: {get_f1_score(c_matrix)}')\n",
    "print(f'With confusion matrix: \\n{c_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that good of a model! We will learn how to improve it in the next lesson on model evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
