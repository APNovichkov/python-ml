{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review of PCA\n",
    "PCA is a way to reduce dimensions in the problem. This means that if we have a lot of features, what we can do is reduce them to n PCA components(for example 2), and plot them to see what we get.\n",
    "\n",
    "PCA is used extensively to find anomalies in the data, because if we plot the 2 PCA components and we see that there is a small cluster of dots separated from the majority of data, we can consider those data points to be anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What it does:\n",
    "- Reduces the number of features while keeping the features information\n",
    "- Removes correlation among features\n",
    "- Emphasizes variations of strong features, making the data easier to visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA finds n top eigenvectors based on their eigenvalues, and those n vectors represent the PCA components!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use Sklearn to get our PCA from a sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>England</th>\n",
       "      <th>N Ireland</th>\n",
       "      <th>Scotland</th>\n",
       "      <th>Wales</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "      <td>135</td>\n",
       "      <td>458</td>\n",
       "      <td>475</td>\n",
       "      <td>Alcoholic drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>73</td>\n",
       "      <td>Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>245</td>\n",
       "      <td>267</td>\n",
       "      <td>242</td>\n",
       "      <td>227</td>\n",
       "      <td>Carcase meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1472</td>\n",
       "      <td>1494</td>\n",
       "      <td>1462</td>\n",
       "      <td>1582</td>\n",
       "      <td>Cereals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>66</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   England  N Ireland  Scotland  Wales          Features\n",
       "0      375        135       458    475  Alcoholic drinks\n",
       "1       57         47        53     73         Beverages\n",
       "2      245        267       242    227      Carcase meat\n",
       "3     1472       1494      1462   1582           Cereals\n",
       "4      105         66       103    103            Cheese"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_excel('pca_uk.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note:**\n",
    "When we are doing PCA, it is important that the X matrix that we give it has these qualities:\n",
    "- Each row is a speficific feature, in this case, it would be a country(England)\n",
    "- Each column represents a class, in this case it oculdn be \"Alcaholic Drinks\", or \"Beverages\", etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X without transpose: [[ 375  135  458  475]\n",
      " [  57   47   53   73]\n",
      " [ 245  267  242  227]\n",
      " [1472 1494 1462 1582]\n",
      " [ 105   66  103  103]\n",
      " [  54   41   62   64]\n",
      " [ 193  209  184  235]\n",
      " [ 147   93  122  160]\n",
      " [1102  674  957 1137]\n",
      " [ 720 1033  566  874]\n",
      " [ 253  143  171  265]\n",
      " [ 685  586  750  803]\n",
      " [ 488  355  418  570]\n",
      " [ 198  187  220  203]\n",
      " [ 360  334  337  365]\n",
      " [1374 1506 1572 1256]\n",
      " [ 156  139  147  175]]\n",
      "X with transpose: [[ 375   57  245 1472  105   54  193  147 1102  720  253  685  488  198\n",
      "   360 1374  156]\n",
      " [ 135   47  267 1494   66   41  209   93  674 1033  143  586  355  187\n",
      "   334 1506  139]\n",
      " [ 458   53  242 1462  103   62  184  122  957  566  171  750  418  220\n",
      "   337 1572  147]\n",
      " [ 475   73  227 1582  103   64  235  160 1137  874  265  803  570  203\n",
      "   365 1256  175]]\n"
     ]
    }
   ],
   "source": [
    "feature_cols = ['England', 'N Ireland', 'Scotland', 'Wales']\n",
    "feature_df = df[feature_cols]\n",
    "\n",
    "X = feature_df.to_numpy()\n",
    "print(f'X without transpose: {X}')\n",
    "X = X.T\n",
    "print(f'X with transpose: {X}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"X_r\" represents the new PCA matrix, where we have n rows where n is the number of features in the original data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-144.99315218,   -2.53299944],\n",
       "       [ 477.39163882,  -58.90186182],\n",
       "       [ -91.869339  ,  286.08178613],\n",
       "       [-240.52914764, -224.64692488]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for feature, (plot_x,plot_y) in enumerate(zip(X_r[:, 0], X_r[:, 1])):\n",
    "    plt.scatter(plot_x, plot_y)\n",
    "    plt.text(plot_x+0.5, plot_y+0.5, df.columns[:-1][feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What conclusions can we make from this plot?**  \n",
    "We can say that N. Ireland is more different from the others in it's food consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Difference in distance among PCA1 axis is greater than distance among PCA2 axis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA is an unsupervised learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The steps that PCA does:\n",
    "1. Use the following matrix: X = np.array([[1, 1, 1], [1, 2, 1], [1, 3, 2], [1, 4, 3]])\n",
    "2. Subtract the column mean from the feature matrix -> this new matrix will be our centered matrix\n",
    "3. Calculate the covariance of the centered matrix.\n",
    "4. Calculate the eigenvalue and eigenvector of the covariance matrix. Remember how we did this in a previous activity!\n",
    "5. Sort the eigevalues so that they are in decresing order, and then find the top N (for example, 2) eigenvectors\n",
    "6. Dot multiply the centered matrix with the top N eigenvectors of the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca(X, n_components=2):\n",
    "    \n",
    "    # Assert that we have enough features for the input components\n",
    "    assert X.shape[0] >= n_components\n",
    "    \n",
    "    # Get the column mean\n",
    "    col_mean = X.mean(axis=0)\n",
    "    \n",
    "    # Get the centered matrix\n",
    "    X_centered = X - col_mean\n",
    "    \n",
    "    # Get the covariance matrix of the centered array\n",
    "    # We want columns to be features and rows to be classes, so we take the Transpose\n",
    "    cov_matrix = np.cov(X_centered.T)\n",
    "    \n",
    "    # Want to obtain the eigen values and eigen vectors\n",
    "    eigen_values, eigen_vectors = np.linalg.eig(cov_matrix)\n",
    "    \n",
    "    # Sort the eigen values and get top 2 eigen vectors\n",
    "    eig_v_to_i = {}\n",
    "    for i, val in enumerate(eigen_values):\n",
    "        eig_v_to_i[val] = i\n",
    "        \n",
    "    eigen_values.sort()\n",
    "    top_eigen_values = eigen_values[::-1][:n_components]\n",
    "    \n",
    "    top_eigen_vectors = []\n",
    "    for val in top_eigen_values:\n",
    "        col_index = eig_v_to_i.get(val)\n",
    "        vector = eigen_vectors[:, col_index]\n",
    "        top_eigen_vectors.append(vector)\n",
    "    top_eigen_vectors = np.array(top_eigen_vectors)\n",
    "\n",
    "    pca_out = np.dot(X_centered, top_eigen_vectors[0:n_components].T)\n",
    "    return pca_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 144.99315218+0.j,   -2.53299944+0.j],\n",
       "       [-477.39163882+0.j,  -58.90186182+0.j],\n",
       "       [  91.869339  +0.j,  286.08178613+0.j],\n",
       "       [ 240.52914764+0.j, -224.64692488+0.j]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = feature_df.to_numpy()\n",
    "get_pca(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-144.99315218,   -2.53299944],\n",
       "       [ 477.39163882,  -58.90186182],\n",
       "       [ -91.869339  ,  286.08178613],\n",
       "       [-240.52914764, -224.64692488]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 144.99315218+0.j,   -2.53299944+0.j],\n",
       "       [-477.39163882+0.j,  -58.90186182+0.j],\n",
       "       [  91.869339  +0.j,  286.08178613+0.j],\n",
       "       [ 240.52914764+0.j, -224.64692488+0.j]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our function to compare \n",
    "def PCA_calculation(data, n_comp=2):\n",
    "    M = np.mean(data, axis=0)\n",
    "    # center columns by subtracting column means\n",
    "    C =  data - M\n",
    "    # calculate covariance matrix of centered matrix\n",
    "    V = np.cov(C.T)\n",
    "#     print(V)\n",
    "    # eigen decomposition of covariance matrix\n",
    "    eig_value, eig_vector = np.linalg.eig(V)\n",
    "    # sort eigenvalue in decreasing order\n",
    "    idx = np.argsort(eig_value)[::-1] \n",
    "    idx_n_comp = idx[:n_comp]\n",
    "    # eigenvectors according to top n_comp largest\n",
    "    eig_vector = eig_vector[:, idx_n_comp]\n",
    "    P = np.dot(C, eig_vector)\n",
    "    return P\n",
    "\n",
    "PCA_calculation(X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question for Office Hours:\n",
    "Why is this output different from sklearn? Should it be? We have complete opposite signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
